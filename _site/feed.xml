<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/">
	<channel>
		<title>Javier Selva Castelló</title>
		<description>Website and blog of Javier Selva.</description>
		<link>http://localhost:4000http://localhost:4000</link>
		<atom:link href="http://localhost:4000http://localhost:4000/feed.xml" rel="self" type="application/rss+xml" />
		
			<item>
				<title>Setting up GitHub Authentication tokens</title>
				
				
					<description>&lt;p&gt;Github tokens are used as a safety measure to connect to repos within your github account. It also allows you to push and pull without the need to write your password or storing it anywhere. Making it a commodity and also a safety feature.&lt;/p&gt;

</description>
				
				<pubDate>Fri, 18 Oct 2024 00:00:00 +0200</pubDate>
				<link>http://localhost:4000http://localhost:4000/blog/tnt/2024/10/18/tnt-git_auth.html</link>
				<guid isPermaLink="true">http://localhost:4000http://localhost:4000/blog/tnt/2024/10/18/tnt-git_auth.html</guid>
			</item>
		
			<item>
				<title>Checking the state of your HDD with badblocks</title>
				
				
					<description>&lt;h1 id=&quot;introduction&quot;&gt;Introduction&lt;/h1&gt;
&lt;p&gt;Since I had an hdd scare and almost lost all of my childhood pictures I started taking backups and disk status seriously. There are many ways to do this. You can pay for cloud storage and let professionals handle it. Or if you’re feeling techie you can set up some raid build so your data replicates automatically. But if like me you’re on a budget, the easiest way I’ve found is to manually hold several copies in different hard drives, and ideally have them in different places.&lt;/p&gt;

</description>
				
				<pubDate>Fri, 04 Oct 2024 00:00:00 +0200</pubDate>
				<link>http://localhost:4000http://localhost:4000/blog/tnt/2024/10/04/tnt-badblocks.html</link>
				<guid isPermaLink="true">http://localhost:4000http://localhost:4000/blog/tnt/2024/10/04/tnt-badblocks.html</guid>
			</item>
		
			<item>
				<title>I-JEPA: Self-Supervised Learning from Images with a Joint-Embedding Predictive Architecture</title>
				
				
					<description>&lt;h1 id=&quot;introduction&quot;&gt;Introduction&lt;/h1&gt;
&lt;p&gt;When LeCun first published his vision of how an embodied agent should function in the world I was excited. It is always nice to escape briefly into reading a little bit of theories and hypothesis on how things should work. It is important, I believe, to take a step back and make sure we’re still going in the direction we wish to follow, instead of banging our heads blindly against the next engeneering problem.&lt;/p&gt;

</description>
				
				<pubDate>Fri, 27 Sep 2024 00:00:00 +0200</pubDate>
				<link>http://localhost:4000http://localhost:4000/blog/paper-summary/2024/09/27/psum-IJEPA.html</link>
				<guid isPermaLink="true">http://localhost:4000http://localhost:4000/blog/paper-summary/2024/09/27/psum-IJEPA.html</guid>
			</item>
		
			<item>
				<title>Using regex to replace multiple instances.</title>
				
				
					<description>&lt;p&gt;This may have happened to me more than one time. I was editing a Latex file and wanted, for instance, to remove a bunch of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;\textbf{bold}&lt;/code&gt; text but keep it as plain text, or accept a bunch of comments (I generally mark working text in red to be later edited/removed/accepted, such as &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;\textcolor{red}{lorem ipsum...}&lt;/code&gt;). My first idea was to use some regex expression to find all these, and somehow parametrize the content so it could be referenced from the replace field of the text editor. In this way, every find-replace would be unique depending on the content each instantiation of the regex in the find had found.&lt;/p&gt;

</description>
				
				<pubDate>Fri, 20 Sep 2024 00:00:00 +0200</pubDate>
				<link>http://localhost:4000http://localhost:4000/blog/tnt/2024/09/20/regex-replace.html</link>
				<guid isPermaLink="true">http://localhost:4000http://localhost:4000/blog/tnt/2024/09/20/regex-replace.html</guid>
			</item>
		
			<item>
				<title>Understanding Softmax Temperature</title>
				
				
					<description>&lt;p&gt;The Softmax function re-normalizes values so they become a probability distribution (sum to 1). In order to achieve this, the softmax function takes three steps. Let’s take a look at this function from multiple perspectives. If you want to follow or play around, the plots for this post were generated using &lt;a href=&quot;http://localhost:4000/assets/notebooks/understanding-softmax-with-temperature.ipynb&quot;&gt;this notebook&lt;/a&gt;.&lt;/p&gt;

</description>
				
				<pubDate>Fri, 13 Sep 2024 00:00:00 +0200</pubDate>
				<link>http://localhost:4000http://localhost:4000/blog/math/2024/09/13/math-softmax.html</link>
				<guid isPermaLink="true">http://localhost:4000http://localhost:4000/blog/math/2024/09/13/math-softmax.html</guid>
			</item>
		
			<item>
				<title>Using ghostscript to hide private data in PDFs</title>
				
				
					<description>&lt;p&gt;This something I’ve frankly had to do several times. Some entity requires a sepecific information from you, information you’ve got in a PDF. However, that file does contain some other sensitive information (e.g., bank transactions) you do not wish to share. It would be very helpful, then, to be able to extract that one or two pages you want to share.&lt;/p&gt;

</description>
				
				<pubDate>Fri, 06 Sep 2024 00:00:00 +0200</pubDate>
				<link>http://localhost:4000http://localhost:4000/blog/tnt/2024/09/06/ghostscript.html</link>
				<guid isPermaLink="true">http://localhost:4000http://localhost:4000/blog/tnt/2024/09/06/ghostscript.html</guid>
			</item>
		
			<item>
				<title>Setting up your site with Jekyll.</title>
				
				
					<description>&lt;p&gt;I recently migrated my simple website (a single plain .html you can see below) into something a bit more stylish.&lt;/p&gt;
&lt;figure&gt;
    &lt;img src=&quot;/assets/img/blog/old-site.png&quot; alt=&quot;A black background image showing a website. There is a picture of a white man smiling, and a list of published papers below, each accompanied by a diagram&quot; style=&quot;border-width: 100px; border-color: white;&quot; /&gt;
    &lt;figcaption&gt;&lt;em&gt;A glance of what the old website looked like.&lt;/em&gt;&lt;/figcaption&gt;
&lt;/figure&gt;

</description>
				
				<pubDate>Fri, 30 Aug 2024 00:00:00 +0200</pubDate>
				<link>http://localhost:4000http://localhost:4000/blog/tech/2024/08/30/tutorial-setup-website.html</link>
				<guid isPermaLink="true">http://localhost:4000http://localhost:4000/blog/tech/2024/08/30/tutorial-setup-website.html</guid>
			</item>
		
			<item>
				<title>Video Transformers: A Survey</title>
				
				
					<description>&lt;p&gt;In this survey, we analyze the main contributions and trends of works leveraging Transformers to model video. Specifically, we delve into how videos are handled at the input level first. Then, we study the architectural changes made to deal with video more efficiently, reduce redundancy, re-introduce useful inductive biases, and capture long-term temporal dynamics. In addition, we provide an overview of different training regimes and explore effective self-supervised learning strategies for video. Finally, we conduct a performance comparison on the most common benchmark for Video Transformers (i.e., action classification), finding them to outperform 3D ConvNets even with less computational complexity.&lt;/p&gt;
</description>
				
				<pubDate>Sun, 01 Jan 2023 00:00:00 +0100</pubDate>
				<link>http://localhost:4000http://localhost:4000/publications/publication/2023/01/01/vt-survey.html</link>
				<guid isPermaLink="true">http://localhost:4000http://localhost:4000/publications/publication/2023/01/01/vt-survey.html</guid>
			</item>
		
			<item>
				<title>Dyadformer: A Multi-modal Transformer for Long-Range Modeling of Dyadic Interactions</title>
				
				
					<description>&lt;p&gt;We present the Dyadformer, a novel multi-modal multi-subject Transformer architecture to model individual and interpersonal features in dyadic interactions using variable time windows, thus allowing the capture of long-term interdependencies. Our proposed cross-subject layer  allows  the  network  to  explicitly  model  interactions among subjects through attentional operations. This proof-of-concept  approach  shows  how  multi-modality  and  joint modeling  of  both  interactants  for  longer  periods  of  time helps to predict individual attributes.&lt;/p&gt;
</description>
				
				<pubDate>Sat, 01 Jan 2022 00:00:00 +0100</pubDate>
				<link>http://localhost:4000http://localhost:4000/publications/2022/01/01/dyadformer.html</link>
				<guid isPermaLink="true">http://localhost:4000http://localhost:4000/publications/2022/01/01/dyadformer.html</guid>
			</item>
		
			<item>
				<title>Context-Aware Personality Inference in Dyadic Scenarios: Introducing the UDIVA Dataset</title>
				
				
					<description>&lt;p&gt;This paper introduces UDIVA, a new non-acted dataset of face-to-face dyadic interactions, where interlocutors perform competitive and collaborative tasks with different behavior elicitation and cognitive workload. The dataset consists of 90.5 hours of dyadic interactions among 147 participants distributed in 188 sessions, recorded using multiple audiovisual and physiological sensors. Currently, it includes sociodemographic, self- and peer-reported personality, internal state, and relationship profiling from participants.&lt;/p&gt;

</description>
				
				<pubDate>Fri, 01 Jan 2021 00:00:00 +0100</pubDate>
				<link>http://localhost:4000http://localhost:4000/publications/publication/2021/01/01/udiva.html</link>
				<guid isPermaLink="true">http://localhost:4000http://localhost:4000/publications/publication/2021/01/01/udiva.html</guid>
			</item>
		
	</channel>
</rss>
