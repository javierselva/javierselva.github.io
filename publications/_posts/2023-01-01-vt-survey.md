---
layout: paper
section-type: paper
has-comments: false
title: "Video Transformers: A Survey"
category: publication
tags: ["transformer","video","survey","self-supervised"]
conference: "TPAMI 2023"
authors: ["Javier Selva","Anders S. Johansen","Sergio Escalera","Kamal Nasrollahi","Thomas B. Moeslund","Albert Clap√©s"]
links:
  Xplore: "https://ieeexplore.ieee.org/document/10041724"
  PDF: "none"
  Supp: "none"
  arXiv: "https://arxiv.org/abs/2201.05991"
  Code: "none"
  Website: "none"
bibtex: ["@article{selva2022video,","title={Video Transformers: A Survey}, ","author={Selva, Javier and Johansen, Anders S. and Escalera, Sergio and Nasrollahi, Kamal and Moeslund, Thomas B. and Clap{\\'e}s, Albert},","year={2023},","journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, ","doi={10.1109/TPAMI.2023.3243465}","}"]
image: "VTsurvey.png"
shortname: "vtsurvey"
---

In this survey, we analyze the main contributions and trends of works leveraging Transformers to model video. Specifically, we delve into how videos are handled at the input level first. Then, we study the architectural changes made to deal with video more efficiently, reduce redundancy, re-introduce useful inductive biases, and capture long-term temporal dynamics. In addition, we provide an overview of different training regimes and explore effective self-supervised learning strategies for video. Finally, we conduct a performance comparison on the most common benchmark for Video Transformers (i.e., action classification), finding them to outperform 3D ConvNets even with less computational complexity.

