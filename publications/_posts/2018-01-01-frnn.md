---
layout: paper
section-type: paper
has-comments: false
title: Folded Recurrent Neural Networks for Future Video Prediction
category: publications
tags: ["paper","rnn","frnn","cnn","frame prediction","video"]
conference: "ECCV 2018"
authors: ["Marc Oliu", "Javier Selva", "Sergio Escalera"]
links:
  PDF: "https://openaccess.thecvf.com/content_ECCV_2018/papers/Marc_Oliu_Folded_Recurrent_Neural_ECCV_2018_paper.pdf"
  Supp: "none"
  arXiv: "https://arxiv.org/abs/1712.00311"
  Code: "https://github.com/moliusimon/frnn"
  Website: "none"
bibtex: ["@inproceedings{oliu2018folded,","title={Folded recurrent neural networks for future video prediction},","author={Oliu, Marc and Selva, Javier and Escalera, Sergio},","booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},","pages={716--731},","year={2018}","}"]
image: "frnn.png"
shortname: "frnn"
---

This work introduces double-mapping Gated Recurrent Units (dGRU), an extension of standard GRUs where the input is considered as a recurrent state. An extra set of logic gates is added to update the input given the output. Stacking multiple such layers results in a recurrent auto-encoder: the operators updating the outputs comprise the encoder, while the ones updating the inputs from the decoder. Since the states are shared between the corresponding encoder and decoder layers, the representation is stratified during learning: some information is not passed to the next layers.
