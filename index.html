<html style="scroll-behavior: smooth">
<head>
    <title>Javier Selva's personal site</title>
</head>

<body>
    <center><h1>Javier Selva</h1>
        <img src="./img/me.png" style="border-radius:50%;"> 
    <h3>PhD Student at Universitat de Barcelona</h3>
    <table border=0>
        <tr>
            <td><a href="https://twitter.com/javier_selvac"><img src="./img/twitter-logo.png" title="Twitter" width="80%"></a></td>
            <td><a href="https://github.com/javierselva"><img src="./img/github-logo.png" title="Github" width="80%"></a></td>
            <td><a href="https://www.linkedin.com/in/javier-selva-castell%C3%B3-399738134/"><img src="./img/linkedin-logo.png" title="Linkedin" width="80%"></a></td>
            <td><a href="https://scholar.google.com/citations?user=T5-DYyUAAAAJ"><img src="./img/scholar-logo.png" title="Google Scholar" width="80%"></a></td>
        </tr>
    </table>
</br> 
<div style="text-align:justify; width:60%">
I received my Bachelor degree in <b>Computer Science</b> at <a href="http://www.upv.es/en">UPV</a> in 2015. Two years later I got my <b>MSc in Artificial Intelligence</b> from <a href="https://www.ub.edu/">UB</a>, <a href="https://www.upc.edu/ca">UPC</a> and <a href="https://www.urv.cat/en/">URV</a>. Currently doing my <b>PhD on Learning Video representations</b> at <a href="http://www.cvc.uab.es/?page_id=223" target="blank">HuPBA</a> lab. under Prof. <a href="https://sergioescalera.com/" target="blank">Sergio Escalera</a>'s supervision. My main <u>research interests</u> include Machine Learning, Natural Language Processing and Computer Vision. I am especially interested in new learning algorithms that do not require supervision, generative models and learning multi-modal representations. <font size="2px"><a href="#bio">More...</a></font>
</div>



<table width="75%" border="0">
    <tr><td><h3>Publications</h3></td><td></td></tr>
    <tr>
        <td valign="top"><img src="./img/papers/dyadformer.png"></td>
        <td valign="top">(ICCV 2021 - DYAD Workshop) <font size="4"><b>Dyadformer: A Multi-modal Transformer for Long-Range Modeling of Dyadic Interactions</b></font></br> 
            David Curto*, Albert Clapés*, <b>Javier Selva</b>*, Sorina Smeureanu, Julio C. S. Jacques Junior, David Gallardo-Pujol, Georgina Guilera, David Leiva, Thomas B. Moeslund, Sergio Escalera and Cristina Palmero</br> 
            <i>We present the Dyadformer, a novel multi-modal multi-subject Transformer architecture to model individual and interpersonal features in dyadic interactions using variable time windows, thus allowing the capture of long-term interdependencies.   Our proposed cross-subject layer  allows  the  network  to  explicitly  model  interactions among subjects through attentional operations. This proof-of-concept  approach  shows  how  multi-modality  and  joint modeling  of  both  interactants  for  longer  periods  of  time helps to predict individual attributes.</i> </br> 
            [<a href="https://openaccess.thecvf.com/content/ICCV2021W/DYAD/papers/Curto_Dyadformer_A_Multi-Modal_Transformer_for_Long-Range_Modeling_of_Dyadic_Interactions_ICCVW_2021_paper.pdf">PDF</a>][<a href="https://arxiv.org/abs/2109.09487">arXiv</a>]
            <details><summary>[Bibtex]</summary>
            <div style="background-color:#EEEEEE;">
                @InProceedings{Curto_2021_ICCV,</br>
                    &emsp;author    = {Curto, David and Clapes, Albert and Selva, Javier and Smeureanu, Sorina and Junior, Julio C. S. Jacques and Gallardo-Pujol, David and Guilera, Georgina and Leiva, David and Moeslund, Thomas B. and Escalera, Sergio and Palmero, Cristina},</br>
                    &emsp;title     = {Dyadformer: A Multi-Modal Transformer for Long-Range Modeling of Dyadic Interactions},</br>
                    &emsp;booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV) Workshops},</br>
                    &emsp;month     = {October},</br>
                    &emsp;year      = {2021},</br>
                    &emsp;pages     = {2177-2188}</br>
                }
            </div>

            </details>
        </td>
    </tr>
    <tr bgcolor="#dddddd"><td></td><td></td></tr>
    <tr>
        <td valign="top"><img src="./img/papers/udiva.png"></td>
        <td valign="top">(WACV 2021 - HBU Workshop) <font size="4"><b>Context-Aware Personality Inference in Dyadic Scenarios: Introducing the UDIVA Dataset</b></font></br> 
            Cristina Palmero∗, <b>Javier Selva</b>∗, Sorina Smeureanu∗, Julio C. S. Jacques Junior, Albert Clapés, Alexa Moseguí, Zejian Zhang, David Gallardo-Pujol, Georgina Guilera, David Leiva and Sergio Escalera</br> 
            <i>This paper introduces UDIVA, a new non-acted dataset of face-to-face dyadic interactions, where interlocutors perform competitive and collaborative tasks with different behavior elicitation and cognitive workload. The dataset consists of 90.5 hours of dyadic interactions among 147 participants distributed in 188 sessions, recorded using multiple audiovisual and physiological sensors. Currently, it includes sociodemographic, self- and peer-reported personality, internal state, and relationship profiling from participants.</i> </br> 
            [<a href="https://openaccess.thecvf.com/content/WACV2021W/HBU/papers/Palmero_Context-Aware_Personality_Inference_in_Dyadic_Scenarios_Introducing_the_UDIVA_Dataset_WACVW_2021_paper.pdf">PDF</a>] [<a href="https://arxiv.org/abs/2012.14259">arXiv</a>] [<a href="https://chalearnlap.cvc.uab.cat/dataset/39/description/">Website</a>] 
            <details><summary>[Bibtex]</summary>
            <div style="background-color:#EEEEEE;">
                @inproceedings{palmero2021context,</br>
                  &emsp;title={Context-Aware Personality Inference in Dyadic Scenarios: Introducing the UDIVA Dataset},</br>
                  &emsp;author={Palmero, Cristina and Selva, Javier and Smeureanu, Sorina and Junior, Julio CS Jacques and Clap{\'e}s, Albert and Mosegu{\'\i}, Alexa and Zhang, Zejian and Gallardo-Pujol, David and Guilera, Georgina and Leiva, David and Escalera, Sergio},</br>
                  &emsp;booktitle={2021 IEEE Winter Conference on Applications of Computer Vision Workshops (WACVW)},</br>
                  &emsp;pages={1--12},</br>
                  &emsp;year={2021},</br>
                  &emsp;organization={IEEE}</br>
                }
            </div>

            </details>
        </td>
    </tr>
    <tr bgcolor="#dddddd"><td></td><td></td></tr>
    <tr>
        <td valign="top"><img src="./img/papers/recurrent-gaze.png"></td>
        <td valign="top">(BMVC 2018) <font size="4"><b>Recurrent CNN for 3D Gaze Estimation using Appearance and Shape Cues</b></font></br> 
            Cristina Palmero, <b>Javier Selva</b>, Mohammad Ali Bagheri and Sergio Escalera</br> 
            <i>In this paper, we tackle the problem of person- and head pose-independent 3D gaze estimation from remote cameras, using a multi-modal recurrent convolutional neural network (CNN). We propose to combine face, eyes region, and face landmarks as individual streams in a CNN to estimate gaze in still images. Then, we exploit the dynamic nature of gaze by feeding the learned features of all the frames in a sequence to a many-to-one recurrent module that predicts the 3D gaze vector of the last frame.</i> </br> 
            [<a href="http://bmvc2018.org/contents/papers/0871.pdf">PDF</a>] [<a href="https://arxiv.org/abs/1805.03064">arXiv</a>] [<a href="https://github.com/crisie/RecurrentGaze">Code</a>] 
            <details><summary>[Bibtex]</summary>
            <div style="background-color:#EEEEEE;">
                @inproceedings{palmero2018recurrent,</br>
                  &emsp;title={Recurrent CNN for 3D Gaze Estimation using Appearance and Shape Cues},</br>
                  &emsp;author={Palmero, Cristina and Selva, Javier and Bagheri, Mohammad Ali and Escalera, Sergio},</br>
                  &emsp;booktitle={Proceedings of the British Machine Vision Conference (BMVC)},</br>
                  &emsp;year={2018}</br>
                }
            </div>

            </details>
        </td>
    </tr>
    <tr bgcolor="#dddddd"><td></td><td></td></tr>
    <tr>
        <td valign="top"><img src="./img/papers/frnn.png"></td>
        <td valign="top">(ECCV 2018) <font size="4"><b>Folded Recurrent Neural Networks for Future Video Prediction</b></font></br> 
            Marc Oliu, <b>Javier Selva</b>, and Sergio Escalera</br> 
            <i>This work introduces double-mapping Gated Recurrent Units (dGRU), an extension of standard GRUs where the input is considered as a recurrent state. An extra set of logic gates is added to update the input given the output. Stacking multiple such layers results in a recurrent auto-encoder: the operators updating the outputs comprise the encoder, while the ones updating the inputs form the decoder. Since the states are shared between corresponding encoder and decoder layers, the representation is stratified during learning: some information is not passed to the next layers.</i> </br> 
            [<a href="https://openaccess.thecvf.com/content_ECCV_2018/papers/Marc_Oliu_Folded_Recurrent_Neural_ECCV_2018_paper.pdf">PDF</a>] [<a href="https://arxiv.org/abs/1712.00311">arXiv</a>] [<a href="https://github.com/moliusimon/frnn">Code</a>] 
            <details><summary>[Bibtex]</summary>
            <div style="background-color:#EEEEEE;">
                @inproceedings{oliu2018folded,</br> 
                  &emsp;title={Folded recurrent neural networks for future video prediction},</br> 
                  &emsp;author={Oliu, Marc and Selva, Javier and Escalera, Sergio},</br> 
                  &emsp;booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},</br> 
                  &emsp;pages={716--731},</br> 
                  &emsp;year={2018}</br> 
                }
            </div>

            </details>
        </td>
    </tr>
</table>
</br> 
</br> 


<!-- New publication template
    &emsp; to tabulate
    <tr>
        <td valign="top"><img src="./img/papers/IMAGE.png"></td>
        <td valign="top">(CONFERENCE AND YEAR) <font size="4"><b>TITLE</b></font></br> 
            AUTHORS</br> 
            <i>MINI ABSTRACT</i> </br> 
            [<a href="OFFICIAL LINK">PDF</a>] [<a href="ARXIV LINK">arXiv</a>] [<a href="CODE">Code</a>] 
            <details><summary>[Bibtex]</summary>
            <div style="background-color:#EEEEEE;">
                BIBTEX
            </div>

            </details>
        </td>
    </tr>
-->

<div style="width:75%;text-align:left"><h3 id="bio">Teaching</h3></div>
<div style="text-align:center; width:60%">
    <table>
        <tr>
            <td><font size=4pt>Lecture</font></td>
            <td><font size=4pt>Slides</font></td>
        </tr>
        <tr>
            <td><iframe width="560" height="315" src="https://www.youtube.com/embed/N92bNxR2MJg" title="Lecture Transformers" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></td>
            <td><iframe width="560" height="315" src="./files/h16_selfAtt_n_transformers_slides.pdf" title="Slides Transformers" frameborder="0" allowfullscreen></iframe></td>
        </tr>
    </table>

</div>

<div style="width:75%;text-align:left"><h3 id="bio">Bio and Interests</h3></div>
<div style="width:60%;text-align:left">
    From a very early age I wanted to be a scientist, and the madder the better. As I grew older I gradually narrowed the path to <b>robots</b>: I was especially interested in making their brains go. From there I went to study Computer Science and got my bachelor degree at Universitat Politècnica de València (<a href="http://www.upv.es/en">UPV</a> - 2015), where I started working on <b>NLP</b>, performing sentiment analysis on Twitter content. From there I came to Barcelona, where I’m currently based, to study a Master on Artificial Intelligence. I was super passionate about the program jointly offered by Universitat Politècnica de Catalunya (<a href="https://www.upc.edu/ca">UPC</a>), Universitat de Barcelona (<a href="https://www.ub.edu/">UB</a>) and Universitat Rovila i Virgili (<a href="https://www.urv.cat/en/">URV</a>), as it ranged from traditional symbolic AI to deep learning, going through multi-agent systems. This gave me an understanding of a wide range of AI techniques and finally allowed me to better define and understand what I was interested in: <b>allowing machines to learn</b>. This got me looking back to <b>neuroscience</b>, and how we humans actually learn. This interest in neuro steered me towards my Master Thesis, which was a <a href="https://upcommons.upc.edu/handle/2117/118121" target="blank">survey on deep video frame prediction (2018)</a>, a task which follows predictive coding ideas to train neural networks for <b>computer vision</b>. After that I jumped on a PhD, which I am currently working on under Prof. <a href="https://sergioescalera.com/" target="blank">Sergio Escalera</a>’s supervision, within the <a href="http://www.cvc.uab.es/?page_id=223" target="blank">HuPBA</a> lab: I am trying to find ways to <b>learn better representations from video</b>. I am curious in nature and being able to integrate knowledge from different fields into our ML algorithms, as well as working on any interdisciplinary project is something I really look forward to. So far I have been working on the <a href="https://chalearnlap.cvc.uab.cat/dataset/39/description/" target="blank">UDIVA project</a>, which involved very enriching work with psychologists. While I’ve found that human analysis may not be my preferred line of research, I have strongly enjoyed working with researchers from other fields, as it has helped me to widen my research views outside my own field.
</br> 
</br> 
    My interests are mostly within the NLP and CV fields as I think the joint use of both could help machines not only get a <b>better understanding</b> of the world, but also provide them with <b>symbolic reasoning</b> capabilities. I am especially interested in <b>learning representations</b>. In particular through <b>reinforcement</b> or <b>(un/self)supervised techniques</b>, possibly aided with strong <b>generative models</b>. I think we should be working towards more <b>computationally efficient</b> architectures which are better capable of <b>generalizing</b> while requiring <b>less data</b>. This in turn, I think, is a step towards <b>democratizing AI</b>, which currently is heavily dependent on data, which in turn is not so much accessible by everyone. Within applied research, I would love to work towards helping humanity make a better use of our resources and try to solve any problem that helps us <b>advance while taking a better care of our environment</b>. 

</div>

</center>
</br> 
</br> </br> 
</br> 
</body>

</html>